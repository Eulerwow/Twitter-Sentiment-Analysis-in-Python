{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d7e9692",
   "metadata": {},
   "source": [
    "# Tweets sentiment analysis\n",
    "\n",
    "##### By Pengyuan Ding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c70c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# pre-processer(TFIDF)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# learners\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78f9b272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set file directors\n",
    "\n",
    "f_dev_tfidf = 'Data/tfidf-tweets/tfidf/dev_tfidf.pkl'\n",
    "f_train_tfidf = 'Data/tfidf-tweets/tfidf/train_tfidf.pkl'\n",
    "f_un_tfidf= 'Data/tfidf-tweets/tfidf/unlabeled_tfidf.pkl'\n",
    "f_test_tfidf= 'Data/tfidf-tweets/tfidf/test_tfidf.pkl'\n",
    "\n",
    "f_dev_emb = 'Data/embedding-tweets/sentence-transformers/dev_emb.pkl'\n",
    "f_train_emb = 'Data/embedding-tweets/sentence-transformers/train_emb.pkl'\n",
    "f_un_emb = 'Data/embedding-tweets/sentence-transformers/unlabeled_emb.pkl'\n",
    "f_test_emb= 'Data/embedding-tweets/sentence-transformers/test_emb.pkl'\n",
    "\n",
    "f_dev_raw = 'Data/raw-tweets/tweets-data/dev.pkl'\n",
    "f_train_raw = 'Data/raw-tweets/tweets-data/train.pkl'\n",
    "f_un_raw = 'Data/raw-tweets/tweets-data/unlabeled.pkl'\n",
    "f_test_raw = 'Data/raw-tweets/tweets-data/test.pkl'\n",
    "\n",
    "f_un_pred_AAE_raw= 'Data/raw-tweets/tweets-data/unlabeled_pred_AAE_raw.pkl'\n",
    "\n",
    "f_dev_mpnet = 'Data/embedding-tweets/mpnet/dev_mpnet.pkl'\n",
    "f_train_mpnet = 'Data/embedding-tweets/mpnet/train_mpnet.pkl'\n",
    "f_un_mpnet = 'Data/embedding-tweets/mpnet/unlabeled_mpnet.pkl'\n",
    "f_test_mpnet = 'Data/embedding-tweets/mpnet/test_mpnet.pkl'\n",
    "\n",
    "f_un_pred_AAE_mpnet = 'Data/embedding-tweets/mpnet/unlabeled_pred_AAE_mpnet.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677d14e3",
   "metadata": {},
   "source": [
    "## Separate TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87334b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = [f_dev_raw, f_train_raw, f_un_raw, f_test_raw]\n",
    "set_name = ['dev', 'train', 'unlabeled', 'test']\n",
    "table_list = []\n",
    "for n in range(len(raw)):\n",
    "    with open(raw[n],'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "        df['Set'] = set_name[n]\n",
    "        table_list.append(df)\n",
    "s = pd.concat(table_list).reset_index()\n",
    "\n",
    "grouped = s.groupby(s.Demographic)  # separate\n",
    "SAE = grouped.get_group(\"SAE\")\n",
    "AAE = grouped.get_group(\"AAE\")\n",
    "SAE = SAE.reset_index()\n",
    "AAE = AAE.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "565cfd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pengy\\AppData\\Local\\Temp/ipykernel_29404/2233889097.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SAE.text[i] = TFIDF_SAE[i]\n"
     ]
    }
   ],
   "source": [
    "vectorizer_SAE = TfidfVectorizer(stop_words = 'english', max_features=1000)\n",
    "TFIDF_SAE = vectorizer_SAE.fit_transform(SAE.text)\n",
    "TFIDF_SAE = TFIDF_SAE.toarray()\n",
    "words_SAE = vectorizer_SAE.get_feature_names_out()\n",
    "\n",
    "for i in range(TFIDF_SAE.shape[0]):\n",
    "    SAE.text[i] = TFIDF_SAE[i]\n",
    "SAE = SAE.rename({'text': 'TFIDF'}, axis=1)\n",
    "\n",
    "SAE_dev = SAE.loc[(SAE['Set'] == 'dev'), ['TFIDF','Sentiment','Demographic']]\n",
    "SAE_dev = SAE_dev.reset_index(drop=True)\n",
    "SAE_train = SAE.loc[(SAE['Set'] == 'train'), ['TFIDF','Sentiment','Demographic']]\n",
    "SAE_train = SAE_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "932d3a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pengy\\AppData\\Local\\Temp/ipykernel_29404/1198378304.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  AAE.text[i] = TFIDF_AAE[i]\n"
     ]
    }
   ],
   "source": [
    "vectorizer_AAE = TfidfVectorizer(stop_words = 'english', max_features=1000)\n",
    "TFIDF_AAE = vectorizer_AAE.fit_transform(AAE.text)\n",
    "TFIDF_AAE = TFIDF_AAE.toarray()\n",
    "words_AAE = vectorizer_AAE.get_feature_names_out()\n",
    "\n",
    "for i in range(TFIDF_AAE.shape[0]):\n",
    "    AAE.text[i] = TFIDF_AAE[i]\n",
    "AAE = AAE.rename({'text': 'TFIDF'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f977cc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlapping: 595\n"
     ]
    }
   ],
   "source": [
    "comm =  list(set(words_AAE).intersection(words_SAE))\n",
    "print('overlapping:',len(comm))\n",
    "AAE_uniq = [i for i in words_AAE if (not i in comm)]\n",
    "SAE_uniq = [i for i in words_SAE if (not i in comm)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceaf8ce",
   "metadata": {},
   "source": [
    "## Baseline (Majority-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c1d0c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Majority-class on SAE set is: 0.5\n",
      "Accuracy of Majority-class on AAE set is: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Separate train data set into two demographic groups\n",
    "with open(f_train_mpnet,'rb') as f:\n",
    "    table = pickle.load(f) \n",
    "grouped = table.groupby(table.Demographic)\n",
    "SAE = grouped.get_group(\"SAE\")\n",
    "AAE = grouped.get_group(\"AAE\")\n",
    "\n",
    "X_train_SAE = np.stack(SAE.TFIDF)\n",
    "y_train_SAE = np.stack(SAE.Sentiment)\n",
    "X_train_AAE = np.stack(AAE.TFIDF)\n",
    "y_train_AAE = np.stack(AAE.Sentiment)\n",
    "\n",
    "MC_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "scores_SAE = cross_val_score(MC_clf, X_train_SAE, y_train_SAE, cv=10)\n",
    "scores_AAE = cross_val_score(MC_clf, X_train_AAE, y_train_SAE, cv=10)\n",
    "print('Accuracy of Majority-class on SAE set is:', np.mean(scores_SAE))\n",
    "print('Accuracy of Majority-class on AAE set is:', np.mean(scores_AAE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf24a6b",
   "metadata": {},
   "source": [
    "## Parameter tuning (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00d70306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data set: 0 metric: cosine best k: 8 with accuracy: 0.6935\n",
      "data set: 0 metric: euclidean best k: 0 with accuracy: 0.6162500000000001\n",
      "data set: 0 metric: manhattan best k: 0 with accuracy: 0.6060000000000001\n",
      "data set: 1 metric: cosine best k: 8 with accuracy: 0.7082499999999999\n",
      "data set: 1 metric: euclidean best k: 8 with accuracy: 0.7205\n",
      "data set: 1 metric: manhattan best k: 8 with accuracy: 0.7255\n",
      "data set: 2 metric: cosine best k: 8 with accuracy: 0.73125\n",
      "data set: 2 metric: euclidean best k: 8 with accuracy: 0.73125\n",
      "data set: 2 metric: manhattan best k: 8 with accuracy: 0.732\n"
     ]
    }
   ],
   "source": [
    "dev_sets = [f_dev_tfidf, f_dev_emb, f_dev_mpnet]  # different data representations\n",
    "metrics = ['cosine','euclidean', 'manhattan']\n",
    "for s in range(len(dev_sets)):\n",
    "    with open(dev_sets[s],'rb') as f:\n",
    "        table = pickle.load(f)\n",
    "    table\n",
    "    X_dev = np.stack(table.TFIDF)\n",
    "    y_dev = np.stack(table.Demographic)\n",
    "    \n",
    "    for m in metrics:\n",
    "        acc = []\n",
    "        for k in range(1,10):\n",
    "            neigh = KNeighborsClassifier(n_neighbors=k, metric=m)\n",
    "\n",
    "            scores = cross_val_score(neigh, X_dev, y_dev, cv=10)\n",
    "            #print('k =',k,'accuracy:',np.mean(scores))\n",
    "            acc.append(np.mean(scores))\n",
    "        max_acc = max(acc)\n",
    "        max_index = acc.index(max_acc)\n",
    "        print('data set:', s, 'metric:', m, 'best k:', max_index, 'with accuracy:', max_acc)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b264b7c7",
   "metadata": {},
   "source": [
    "Choose k=8 with cosine distance metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21742047",
   "metadata": {},
   "source": [
    "## Learn on whole demographic set - original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc11c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = [f_train_tfidf, f_train_emb, f_train_mpnet]  \n",
    "dev_sets = [f_dev_tfidf, f_dev_emb, f_dev_mpnet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da7c05d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_whole(clf):\n",
    "    for n in range(len(train_sets)):\n",
    "        with open(train_sets[n],'rb') as f:\n",
    "            table = pickle.load(f) \n",
    "        X_train = np.stack(table.TFIDF)\n",
    "        y_train = np.stack(table.Sentiment)\n",
    "\n",
    "        with open(dev_sets[n],'rb') as f:\n",
    "            table_dev = pickle.load(f) \n",
    "        X_dev = np.stack(table_dev.TFIDF)\n",
    "        y_dev = np.stack(table_dev.Sentiment)\n",
    "\n",
    "        grouped = table_dev.groupby(table_dev.Demographic)  # separate\n",
    "        SAE = grouped.get_group(\"SAE\")\n",
    "        AAE = grouped.get_group(\"AAE\")\n",
    "        SAE = SAE.reset_index()\n",
    "        AAE = AAE.reset_index()\n",
    "        X_SAE = np.stack(SAE.TFIDF)\n",
    "        y_SAE = np.stack(SAE.Sentiment)\n",
    "        X_AAE = np.stack(AAE.TFIDF)\n",
    "        y_AAE = np.stack(AAE.Sentiment)\n",
    "\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        pred = clf.predict(X_dev)\n",
    "        pred_SAE = clf.predict(X_SAE)\n",
    "        pred_AAE = clf.predict(X_AAE)\n",
    "\n",
    "        acc = accuracy_score(y_dev, pred)\n",
    "        acc_SAE = accuracy_score(y_SAE, pred_SAE)\n",
    "        acc_AAE = accuracy_score(y_AAE, pred_AAE)\n",
    "\n",
    "        print('data set:',n , 'total accuray:', acc, 'SAE accuray:', acc_SAE, 'AAE accuracy:', acc_AAE)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e5026f",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1edf2e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data set: 0 total accuray: 0.6205 SAE accuray: 0.6455 AAE accuracy: 0.5955\n",
      "data set: 1 total accuray: 0.6725 SAE accuray: 0.7 AAE accuracy: 0.645\n",
      "data set: 2 total accuray: 0.6745 SAE accuray: 0.716 AAE accuracy: 0.633\n"
     ]
    }
   ],
   "source": [
    "#create KNN classifier\n",
    "clf = KNeighborsClassifier(n_neighbors=8, metric='cosine')\n",
    "run_whole(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a7d153",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "Assumptions:\n",
    "1. conditional independence\n",
    "    Not appropriate, (e.g. given sentiment=Negative, words 'angry' and 'fury' are clearly correlated.)\n",
    "2. Distribution\n",
    "    1. p(y) - bernuoli\n",
    "    2. p(x|y) - Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e22fffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data set: 0 total accuray: 0.64525 SAE accuray: 0.679 AAE accuracy: 0.6115\n",
      "data set: 1 total accuray: 0.61475 SAE accuray: 0.652 AAE accuracy: 0.5775\n",
      "data set: 2 total accuray: 0.61 SAE accuray: 0.65 AAE accuracy: 0.57\n"
     ]
    }
   ],
   "source": [
    "#Create a Gaussian Classifier\n",
    "clf = GaussianNB()\n",
    "run_whole(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d3685d",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6a2a70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data set: 0 total accuray: 0.67875 SAE accuray: 0.7095 AAE accuracy: 0.648\n",
      "data set: 1 total accuray: 0.69825 SAE accuray: 0.732 AAE accuracy: 0.6645\n",
      "data set: 2 total accuray: 0.7205 SAE accuray: 0.7635 AAE accuracy: 0.6775\n"
     ]
    }
   ],
   "source": [
    "#Create a Logistic Regression Classifier\n",
    "clf = LogisticRegression(random_state=0, max_iter=1000)\n",
    "run_whole(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f04d3e",
   "metadata": {},
   "source": [
    "## Learn on separate data sets (Excluding new TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df1dfa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_separate(clf):\n",
    "    for n in range(len(train_sets)):\n",
    "        with open(train_sets[n],'rb') as f:\n",
    "            table = pickle.load(f)\n",
    "        grouped = table.groupby(table.Demographic)\n",
    "        SAE = grouped.get_group(\"SAE\")\n",
    "        AAE = grouped.get_group(\"AAE\")\n",
    "\n",
    "        X_SAE = np.stack(SAE.TFIDF)\n",
    "        y_SAE = np.stack(SAE.Sentiment)\n",
    "\n",
    "        scores_SAE = cross_val_score(clf, X_SAE, y_SAE, cv=10)\n",
    "        acc_SAE = np.mean(scores_SAE)\n",
    "\n",
    "        X_AAE = np.stack(AAE.TFIDF)\n",
    "        y_AAE = np.stack(AAE.Sentiment)\n",
    "\n",
    "        scores_AAE = cross_val_score(clf, X_AAE, y_AAE, cv=10)\n",
    "        acc_AAE = np.mean(scores_AAE)    \n",
    "\n",
    "        print('data set:',n , 'SAE accuray:', acc_SAE, 'AAE accuracy:', acc_AAE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6449184a",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cd13cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data set: 0 SAE accuray: 0.65295 AAE accuracy: 0.5955999999999999\n",
      "data set: 1 SAE accuray: 0.702 AAE accuracy: 0.6266499999999999\n",
      "data set: 2 SAE accuray: 0.7162 AAE accuracy: 0.6256\n"
     ]
    }
   ],
   "source": [
    "# create KNN classifier\n",
    "clf = KNeighborsClassifier(n_neighbors=8, metric='cosine')\n",
    "run_separate(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1307550d",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57a7a25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data set: 0 SAE accuray: 0.64355 AAE accuracy: 0.59595\n",
      "data set: 1 SAE accuray: 0.6583 AAE accuracy: 0.59235\n",
      "data set: 2 SAE accuray: 0.6634 AAE accuracy: 0.58455\n"
     ]
    }
   ],
   "source": [
    "#Create a Gaussian Classifier\n",
    "clf = GaussianNB()\n",
    "run_separate(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1e3cd0",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a22f1195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data set: 0 SAE accuray: 0.70685 AAE accuracy: 0.6393\n",
      "data set: 1 SAE accuray: 0.7386 AAE accuracy: 0.6567500000000001\n",
      "data set: 2 SAE accuray: 0.76825 AAE accuracy: 0.6768\n"
     ]
    }
   ],
   "source": [
    "#Create a Logistic Regression Classifier\n",
    "clf = LogisticRegression(random_state=0, max_iter=1000)\n",
    "run_separate(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0fe2d1",
   "metadata": {},
   "source": [
    "## Learn on  new TFIDF (Separate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a66eb3",
   "metadata": {},
   "source": [
    "#### Create separate TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d5f6bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = [f_dev_raw, f_train_raw, f_un_raw, f_test_raw]\n",
    "set_name = ['dev', 'train', 'unlabeled', 'test']\n",
    "table_list = []\n",
    "for n in range(len(raw)):\n",
    "    with open(raw[n],'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "        df['Set'] = set_name[n]\n",
    "        table_list.append(df)\n",
    "s = pd.concat(table_list).reset_index()\n",
    "\n",
    "grouped = s.groupby(s.Demographic)  # separate\n",
    "SAE = grouped.get_group(\"SAE\")\n",
    "AAE = grouped.get_group(\"AAE\")\n",
    "SAE = SAE.reset_index()\n",
    "AAE = AAE.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3f86b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pengy\\AppData\\Local\\Temp/ipykernel_29404/2233889097.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SAE.text[i] = TFIDF_SAE[i]\n"
     ]
    }
   ],
   "source": [
    "vectorizer_SAE = TfidfVectorizer(stop_words = 'english', max_features=1000)\n",
    "TFIDF_SAE = vectorizer_SAE.fit_transform(SAE.text)\n",
    "TFIDF_SAE = TFIDF_SAE.toarray()\n",
    "words_SAE = vectorizer_SAE.get_feature_names_out()\n",
    "\n",
    "for i in range(TFIDF_SAE.shape[0]):\n",
    "    SAE.text[i] = TFIDF_SAE[i]\n",
    "SAE = SAE.rename({'text': 'TFIDF'}, axis=1)\n",
    "\n",
    "SAE_dev = SAE.loc[(SAE['Set'] == 'dev'), ['TFIDF','Sentiment','Demographic']]\n",
    "SAE_dev = SAE_dev.reset_index(drop=True)\n",
    "SAE_train = SAE.loc[(SAE['Set'] == 'train'), ['TFIDF','Sentiment','Demographic']]\n",
    "SAE_train = SAE_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "141af7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pengy\\AppData\\Local\\Temp/ipykernel_29404/1710939224.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  AAE.text[i] = TFIDF_AAE[i]\n"
     ]
    }
   ],
   "source": [
    "vectorizer_AAE = TfidfVectorizer(stop_words = 'english', max_features=1000)\n",
    "TFIDF_AAE = vectorizer_AAE.fit_transform(AAE.text)\n",
    "TFIDF_AAE = TFIDF_AAE.toarray()\n",
    "words_AAE = vectorizer_AAE.get_feature_names_out()\n",
    "\n",
    "for i in range(TFIDF_AAE.shape[0]):\n",
    "    AAE.text[i] = TFIDF_AAE[i]\n",
    "AAE = AAE.rename({'text': 'TFIDF'}, axis=1)\n",
    "AAE_dev = AAE.loc[(AAE['Set'] == 'dev'), ['TFIDF','Sentiment','Demographic']]\n",
    "AAE_dev = AAE_dev.reset_index(drop=True)\n",
    "AAE_train = AAE.loc[(AAE['Set'] == 'train'), ['TFIDF','Sentiment','Demographic']]\n",
    "AAE_train = AAE_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1261d07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlapping: 595\n"
     ]
    }
   ],
   "source": [
    "comm =  list(set(words_AAE).intersection(words_SAE))\n",
    "print('overlapping:',len(comm))\n",
    "AAE_uniq = [i for i in words_AAE if (not i in comm)]\n",
    "SAE_uniq = [i for i in words_SAE if (not i in comm)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bed9fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_new_tfidf(clf):\n",
    "\n",
    "    X_SAE = np.stack(SAE_train.TFIDF)\n",
    "    y_SAE = np.stack(SAE_train.Sentiment)\n",
    "\n",
    "    scores_SAE = cross_val_score(clf, X_SAE, y_SAE, cv=10)\n",
    "    acc_SAE = np.mean(scores_SAE)\n",
    "\n",
    "    X_AAE = np.stack(AAE_train.TFIDF)\n",
    "    y_AAE = np.stack(AAE_train.Sentiment)\n",
    "\n",
    "    scores_AAE = cross_val_score(clf, X_AAE, y_AAE, cv=10)\n",
    "    acc_AAE = np.mean(scores_AAE)    \n",
    "\n",
    "    print('SAE accuray:', acc_SAE, 'AAE accuracy:', acc_AAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276c95c",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc8a12a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE accuray: 0.6596499999999998 AAE accuracy: 0.5982999999999999\n"
     ]
    }
   ],
   "source": [
    "# create KNN classifier\n",
    "clf = KNeighborsClassifier(n_neighbors=8, metric='cosine')\n",
    "run_new_tfidf(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f59788b",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1fbd23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE accuray: 0.675 AAE accuracy: 0.61175\n"
     ]
    }
   ],
   "source": [
    "#Create a Gaussian Classifier\n",
    "clf = GaussianNB()\n",
    "run_new_tfidf(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd49512",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e84f7d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE accuray: 0.7091500000000001 AAE accuracy: 0.6403000000000001\n"
     ]
    }
   ],
   "source": [
    "#Create a Logistic Regression Classifier\n",
    "clf = LogisticRegression(random_state=0, max_iter=1000)\n",
    "run_new_tfidf(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a534c5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf38672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e55b6605",
   "metadata": {},
   "source": [
    "### Semi-supervised (Self-training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfcdcad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "clf = LogisticRegression(random_state=0, max_iter=1000)\n",
    "st_clf = SelfTrainingClassifier(clf, threshold=0.85, criterion='threshold', max_iter=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5969b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of iteration 1, added 20533 new labels.\n",
      "End of iteration 2, added 34209 new labels.\n",
      "End of iteration 3, added 17975 new labels.\n",
      "End of iteration 4, added 6487 new labels.\n",
      "End of iteration 5, added 2477 new labels.\n",
      "End of iteration 6, added 1214 new labels.\n",
      "End of iteration 7, added 694 new labels.\n",
      "End of iteration 8, added 368 new labels.\n",
      "End of iteration 9, added 206 new labels.\n",
      "End of iteration 10, added 121 new labels.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.66625"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f_dev_emb,'rb') as f:\n",
    "    table = pickle.load(f)\n",
    "X = np.stack(table.TFIDF)\n",
    "y = np.stack(table.Sentiment)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "with open(f_un_emb,'rb') as f:\n",
    "    untable = pickle.load(f)\n",
    "\n",
    "X_un = np.stack(untable.TFIDF)\n",
    "y_un = np.full(untable.Sentiment.shape , -1)\n",
    "\n",
    "\n",
    "X_comb = np.concatenate((X_train, X_un))\n",
    "y_comb = np.concatenate((y_train, y_un), dtype=object)\n",
    "\n",
    "st_clf.fit(X_comb, y_comb)\n",
    "st_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a0f7f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d80e9f82",
   "metadata": {},
   "source": [
    "### Predict dialect group to select candidate data for semi-supervised learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c940fe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f_train_mpnet,'rb') as f:\n",
    "    table = pickle.load(f) \n",
    "X_train = np.stack(table.TFIDF)\n",
    "y_train = np.stack(table.Demographic)\n",
    "\n",
    "\n",
    "with open(f_un_mpnet,'rb') as f:\n",
    "    table = pickle.load(f) \n",
    "X_test = np.stack(table.TFIDF)\n",
    "y_test = np.stack(table.Demographic)\n",
    "\n",
    "clf = LogisticRegression(random_state=0, max_iter=1000)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "pp = clf.predict_proba(X_test)\n",
    "prd = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e6530aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = pp.shape[0]\n",
    "slc = []\n",
    "for i in range(l):\n",
    "    slc.append(pp[i,0] >= 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02728035",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f_un_mpnet,'rb') as f:\n",
    "    table_mpnet = pickle.load(f) \n",
    "table_mpnet.Demographic[slc] = 'AAE'\n",
    "table_mpnet.to_pickle(f_un_pred_AAE_mpnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a103f77d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Demographic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3:16 for mommy</td>\n",
       "      <td>None</td>\n",
       "      <td>AAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kmsl Olivia got me pissy weak</td>\n",
       "      <td>None</td>\n",
       "      <td>AAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Good morning ppl ... Feeling kinda down this m...</td>\n",
       "      <td>None</td>\n",
       "      <td>AAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\\ _TWITTER-ENTITY_ : Niggas mad ashit they don...</td>\n",
       "      <td>None</td>\n",
       "      <td>AAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Bitches be mad because they set they self up</td>\n",
       "      <td>None</td>\n",
       "      <td>AAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99968</th>\n",
       "      <td>But I miss Tweety I need To G See Her And My G...</td>\n",
       "      <td>None</td>\n",
       "      <td>AAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99971</th>\n",
       "      <td>Taj is killing me tonight</td>\n",
       "      <td>None</td>\n",
       "      <td>AAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973</th>\n",
       "      <td>Left alone with big fat fatty . She was such a...</td>\n",
       "      <td>None</td>\n",
       "      <td>AAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99983</th>\n",
       "      <td>â _TWITTER-ENTITY_ : _TWITTER-ENTITY_ _TWITT...</td>\n",
       "      <td>None</td>\n",
       "      <td>AAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99994</th>\n",
       "      <td>â _TWITTER-ENTITY_ : Kailyn def had the extr...</td>\n",
       "      <td>None</td>\n",
       "      <td>AAE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24140 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text Sentiment Demographic\n",
       "6                                         3:16 for mommy      None         AAE\n",
       "10                         Kmsl Olivia got me pissy weak      None         AAE\n",
       "20     Good morning ppl ... Feeling kinda down this m...      None         AAE\n",
       "21     \\ _TWITTER-ENTITY_ : Niggas mad ashit they don...      None         AAE\n",
       "25          Bitches be mad because they set they self up      None         AAE\n",
       "...                                                  ...       ...         ...\n",
       "99968  But I miss Tweety I need To G See Her And My G...      None         AAE\n",
       "99971                          Taj is killing me tonight      None         AAE\n",
       "99973  Left alone with big fat fatty . She was such a...      None         AAE\n",
       "99983  â _TWITTER-ENTITY_ : _TWITTER-ENTITY_ _TWITT...      None         AAE\n",
       "99994  â _TWITTER-ENTITY_ : Kailyn def had the extr...      None         AAE\n",
       "\n",
       "[24140 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f_un_raw,'rb') as f:\n",
    "    table_raw = pickle.load(f) \n",
    "table_raw.Demographic[slc] = 'AAE'\n",
    "table_raw.to_pickle(f_un_pred_AAE_raw)\n",
    "with open(f_un_pred_AAE_raw,'rb') as f:\n",
    "    table_raw = pickle.load(f) \n",
    "table_raw[slc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a3ac9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pengy\\AppData\\Local\\Temp/ipykernel_29404/639837155.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  AAE.text[i] = TFIDF_AAE[i]\n"
     ]
    }
   ],
   "source": [
    "# create full AAE data\n",
    "\n",
    "raw = [f_dev_raw, f_train_raw, f_un_raw, f_test_raw, f_un_pred_AAE_raw]\n",
    "set_name = ['dev', 'train', 'unlabeled', 'test', 'pred']\n",
    "table_list = []\n",
    "for n in range(len(raw)):\n",
    "    with open(raw[n],'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "        df['Set'] = set_name[n]\n",
    "        table_list.append(df)\n",
    "s = pd.concat(table_list).reset_index()\n",
    "\n",
    "grouped = s.groupby(s.Demographic)\n",
    "SAE = grouped.get_group(\"SAE\")\n",
    "AAE = grouped.get_group(\"AAE\")\n",
    "SAE = SAE.reset_index()\n",
    "AAE = AAE.reset_index()\n",
    "vectorizer_AAE = TfidfVectorizer(stop_words = 'english', max_features=1000)\n",
    "TFIDF_AAE = vectorizer_AAE.fit_transform(AAE.text)\n",
    "TFIDF_AAE = TFIDF_AAE.toarray()\n",
    "words_AAE = vectorizer_AAE.get_feature_names_out()\n",
    "for i in range(TFIDF_AAE.shape[0]):\n",
    "    AAE.text[i] = TFIDF_AAE[i]\n",
    "AAE = AAE.rename({'text': 'TFIDF'}, axis=1)\n",
    "\n",
    "AAE_dev = AAE.loc[(AAE['Set'] == 'dev'), ['TFIDF','Sentiment','Demographic']]\n",
    "AAE_dev = AAE_dev.reset_index(drop=True)\n",
    "\n",
    "AAE_train = AAE.loc[(AAE['Set'] == 'train'), ['TFIDF','Sentiment','Demographic']]\n",
    "AAE_train = AAE_train.reset_index(drop=True)\n",
    "\n",
    "AAE_unlabeled = AAE.loc[(AAE['Set'] == 'pred'), ['TFIDF','Sentiment','Demographic']]\n",
    "AAE_unlabeled = AAE_unlabeled.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19fb2b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6045"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf = GaussianNB()\n",
    "clf = LogisticRegression(random_state=0, max_iter=1000)\n",
    "#clf = KNeighborsClassifier(n_neighbors=51, weights = 'distance', metric='cosine')\n",
    "\n",
    "X_dev = np.stack(AAE_dev.TFIDF)\n",
    "y_dev = np.stack(AAE_dev.Sentiment)\n",
    "scores = cross_val_score(clf, X_dev, y_dev, cv=10)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39b441d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of iteration 1, added 211 new labels.\n",
      "End of iteration 2, added 528 new labels.\n",
      "End of iteration 3, added 673 new labels.\n",
      "End of iteration 4, added 670 new labels.\n",
      "End of iteration 5, added 634 new labels.\n",
      "End of iteration 6, added 576 new labels.\n",
      "End of iteration 7, added 328 new labels.\n",
      "End of iteration 8, added 222 new labels.\n",
      "End of iteration 9, added 177 new labels.\n",
      "End of iteration 10, added 131 new labels.\n",
      "End of iteration 11, added 88 new labels.\n",
      "End of iteration 12, added 69 new labels.\n",
      "End of iteration 13, added 26 new labels.\n",
      "End of iteration 14, added 27 new labels.\n",
      "End of iteration 15, added 21 new labels.\n",
      "End of iteration 16, added 13 new labels.\n",
      "End of iteration 17, added 12 new labels.\n",
      "End of iteration 18, added 2 new labels.\n",
      "End of iteration 19, added 1 new labels.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.595"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "clf = LogisticRegression(random_state=0, max_iter=1000)\n",
    "st_clf = SelfTrainingClassifier(clf, threshold=0.85, criterion='threshold', max_iter=50, verbose=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dev, y_dev, test_size=0.2, random_state=0)\n",
    "\n",
    "X_un = np.stack(AAE_train.TFIDF)\n",
    "y_un = np.full(AAE_train.Sentiment.shape , -1)\n",
    "\n",
    "\n",
    "X_comb = np.concatenate((X_train, X_un))\n",
    "y_comb = np.concatenate((y_train, y_un), dtype=object)\n",
    "\n",
    "st_clf.fit(X_comb, y_comb)\n",
    "st_clf.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
